Comprehensive Architectural Design and Implementation Strategy for the Aria Threading and Concurrency Library
Executive Summary
This report presents a definitive architectural blueprint for the Aria programming language's concurrency and threading subsystem. Following a rigorous analysis of modern systems programming paradigms—specifically examining the evolution of Go's goroutines, Rust's Tokio runtime, and Java's Project Loom—this document prescribes a Hybrid M:N Threading Model underpinned by a work-stealing scheduler. This architecture is designed to reconcile the conflicting demands of high-throughput asynchronous I/O and low-latency, CPU-intensive parallel processing, addressing the critical gap in the current Aria specification regarding thread-based parallelism.
The proposed design leverages Aria's existing async/await syntax and Twisted Balanced Binary (TBB) type system while introducing a bifurcated API surface: aria.task for lightweight, cooperative coroutines (M:N), and aria.thread for deterministic, preemptive OS threads (1:1). This dual approach mitigates the "colored function" problem inherent in async ecosystems by providing explicit bridging mechanisms like spawn_blocking, ensuring that the cooperative scheduler remains unblocked by heavy computations or legacy system calls.
Furthermore, this report details the implementation of synchronization primitives—Mutexes, Channels, and Semaphores—that are explicitly aware of the dual-mode runtime. It integrates these primitives with Aria's unique "Appendage Theory" memory safety model, ensuring that data race freedom is enforced at compile-time without the runtime overhead of a garbage collector for shared resources. The resulting architecture positions Aria to compete directly with Rust and Go in the domain of high-performance networked services and systems programming.
________________
1. Introduction: The Concurrency Landscape and Aria's Position
The evolution of hardware architecture over the last two decades, characterized by the stagnation of single-core clock speeds and the explosion of core counts (Amdahl's Law limitations), has necessitated a paradigm shift in software design. Concurrency is no longer an optimization; it is a structural requirement. For a new systems language like Aria, the choice of concurrency model is arguably the most significant determinant of its long-term viability and adoption.1
1.1 The Spectrum of Concurrency Models
Historically, language designers have oscillated between two dominant models:
1. System Threads (1:1 Model): Used by C++, Java (pre-Loom), and Rust's standard library. Here, one language thread corresponds directly to one Kernel Execution Entity (KSE). The OS kernel handles scheduling, preemption, and resource allocation.
   * Advantages: Excellent FFI compatibility, predictable performance, leverages hardware preemption.2
   * Disadvantages: High memory footprint (megabytes per thread), slow context switching (microseconds), and scalability limits (typically <10k threads).4
2. User-Space Threads (M:N Model): Used by Go (Goroutines), Erlang, and Haskell. The language runtime multiplexes $M$ lightweight user threads onto $N$ kernel threads.
   * Advantages: Massive scalability (millions of tasks), fast context switching (nanoseconds), dynamic stack growth.6
   * Disadvantages: Runtime complexity, difficulty integrating with blocking C code (FFI), and non-deterministic latency spikes due to garbage collection or scheduler intervention.8
1.2 Aria's Architectural Imperative
Aria occupies a unique niche. It features a high-performance backend using LLVM, manual memory management options via wild pointers, and a novel "Appendage Theory" for safety.10 It also mandates async/await as a core language feature.10
A purely 1:1 model would render the async keyword redundant, forcing developers to manage heavy OS threads for I/O, which is inefficient. Conversely, a pure M:N model (like Go) effectively hides the underlying hardware, which contradicts Aria's goal of being a systems language capable of bare-metal performance.
Therefore, the analysis indicates that Aria must adopt a Hybrid Model. This model uses M:N scheduling for async tasks to handle I/O and massive concurrency, while retaining the ability to spawn 1:1 OS threads for CPU-bound workloads that demand affinity and isolation. This mirrors the trajectory of Rust (via Tokio) and modern C++ (via libraries like libfork or taskflow), providing "zero-cost abstractions" where the developer pays only for the concurrency model they utilize.11
________________
2. Architectural Design: The Hybrid Concurrency Model
The proposed Aria Concurrency System (ACS) is composed of two distinct but interoperable layers: the Task Runtime (M:N) and the Thread Subsystem (1:1).
2.1 The Task Runtime (M:N)
The Task Runtime is the engine behind Aria's async/await syntax. It is designed to execute non-blocking, cooperative tasks.
* Unit of Execution: The Task. This is a stackless coroutine compiled into a state machine by the LLVM backend.13 It is lightweight (allocation size ~200-500 bytes) and creates no OS handles.
* Scheduling Algorithm: Work-Stealing. This is the industry standard for dynamic load balancing.14 The runtime spawns $N$ worker threads (typically equal to the number of logical CPU cores). Each worker maintains a local double-ended queue (deque) of tasks.
   * Hot Path: Workers push and pop tasks from the bottom of their local deque in LIFO order. This maximizes cache locality (executing the child task while data is still hot in L1/L2 cache).16
   * Cold Path: When a worker runs out of tasks, it becomes a "thief," stealing tasks from the top of another worker's deque (FIFO order). This ensures that "stale" tasks are picked up by idle workers, balancing the load.15
2.2 The Thread Subsystem (1:1)
The Thread Subsystem exposes the underlying operating system's threading capabilities directly.
* Unit of Execution: The Thread. This maps to pthread_create (POSIX) or CreateThread (Windows).
* Use Cases: Long-running CPU computations (matrix multiplication, cryptography), FFI calls to blocking C libraries, and real-time tasks requiring thread priority adjustments.12
2.3 The Bridge: spawn_blocking
To prevent the "colored function" dilemma from fracturing the ecosystem, the architecture includes an explicit bridge. The spawn_blocking function allows an async task to offload a synchronous operation to a dedicated, dynamic thread pool. This ensures that the fixed-size M:N scheduler is never blocked by long-running operations, preserving the latency guarantees of the async runtime.19
________________
3. Scheduler Implementation: Algorithms and Data Structures
The core of the M:N runtime is the scheduler. Based on the analysis of staccato, libfork, and tokio, the recommended implementation for Aria's backend uses the Chase-Lev Deque.
3.1 The Chase-Lev Work-Stealing Deque
The Chase-Lev deque is a lock-free data structure designed specifically for work-stealing scenarios where there is one owner (pusher/popper) and multiple thieves.21
Data Structure (C++ Backend Representation):


C++




template <typename T>
class WorkStealingDeque {
   // Cyclic buffer storing tasks (pointers to CoroutineFrames)
   std::atomic<T*> buffer;
   std::atomic<size_t> top;    // Accessed by thieves
   std::atomic<size_t> bottom; // Accessed by owner
   size_t capacity;

public:
   // Pushes a task to the bottom (Owner only)
   // Memory Order: Relaxed is mostly sufficient, except for publishing
   void push(T task) {
       size_t b = bottom.load(std::memory_order_relaxed);
       size_t t = top.load(std::memory_order_acquire);
       if (b - t >= capacity - 1) {
           resize(); // Heavy operation, implies locking
       }
       buffer[b % capacity].store(task, std::memory_order_relaxed);
       std::atomic_thread_fence(std::memory_order_release);
       bottom.store(b + 1, std::memory_order_relaxed);
   }

   // Pops a task from the bottom (Owner only)
   T pop() {
       size_t b = bottom.load(std::memory_order_relaxed) - 1;
       bottom.store(b, std::memory_order_relaxed);
       std::atomic_thread_fence(std::memory_order_seq_cst);
       size_t t = top.load(std::memory_order_relaxed);
       
       if (t > b) { // Empty
           bottom.store(b + 1, std::memory_order_relaxed);
           return nullptr;
       }
       
       T task = buffer[b % capacity].load(std::memory_order_relaxed);
       if (t == b) { // Race condition: Last item, thief might be stealing it
           if (!top.compare_exchange_strong(t, t + 1, 
                                            std::memory_order_seq_cst, 
                                            std::memory_order_relaxed)) {
               // We lost the race to a thief
               bottom.store(b + 1, std::memory_order_relaxed);
               return nullptr;
           }
           bottom.store(b + 1, std::memory_order_relaxed);
       }
       return task;
   }

   // Steals a task from the top (Any thread)
   T steal() {
       size_t t = top.load(std::memory_order_acquire);
       std::atomic_thread_fence(std::memory_order_seq_cst);
       size_t b = bottom.load(std::memory_order_acquire);
       
       if (t >= b) return nullptr; // Empty
       
       T task = buffer[t % capacity].load(std::memory_order_relaxed);
       if (!top.compare_exchange_strong(t, t + 1, 
                                        std::memory_order_seq_cst, 
                                        std::memory_order_relaxed)) {
           return nullptr; // Lost race to another thief
       }
       return task;
   }
};

Implementation Note: The use of seq_cst (Sequential Consistency) fences is critical in the pop and steal paths to prevent the "ABA problem" and ensure that the owner thread correctly detects a concurrent steal operation on the last element.15
3.2 Scheduler Loop and Global Injection
While local queues handle the majority of traffic, tasks can also originate from outside the runtime (e.g., from the main thread or an FFI callback). For this, the scheduler must include a Global Injection Queue. This is a thread-safe MPMC (Multi-Producer Multi-Consumer) queue protected by a mutex or lock-free linked list.23
Fairness Mechanism:
To prevent starvation of the Global Queue (where externally spawned tasks live), workers must check the global queue periodically. A common heuristic (used by Go) is to check the global queue once every 61 scheduler ticks.24
Worker Loop Logic:
1. Check Global Queue (periodically).
2. Check Local Queue (pop bottom).
3. If empty, scan other workers' queues (steal top).
4. If still empty, park the thread (wait on CondVar/Semaphore) to save CPU cycles.25
________________
4. API Design Specifications
The following APIs are designed to integrate seamlessly with Aria's syntax, utilizing its type system features like Result, Future, and Generics.
4.1 The Threading Module: aria.thread
This module provides explicit control over OS threads.


Code snippet




mod thread {
   // Handle to a running OS thread. 
   // <T> indicates the return type of the thread's function.
   pub struct JoinHandle<T> {
       wild void*: native_handle; // Opaque pointer to pthread_t / HANDLE
       
       // Waits for the thread to finish and returns its result.
       // Blocking operation.
       pub func:join = Result<T>(self) {... }
   }

   // Spawns a new OS thread.
   // 'func:f' is the closure to execute.
   // Returns a Result containing the JoinHandle or an error.
   pub func:spawn<T> = Result<JoinHandle<T>>(func:f) {... }

   // Yields the current OS timeslice.
   pub func:yield_now = void() {... }

   // Sleeps the current OS thread.
   pub func:sleep = void(int64:milliseconds) {... }
   
   // Gets the current thread's ID.
   pub func:id = uint64() {... }
}

Comparison:
* Vs Rust: Similar to std::thread::spawn. Aria's Result type wrapper enforces error handling for thread creation failures (e.g., OOM), which Rust panics on by default in some configurations.
* Vs Java: Unlike new Thread(), Aria's threads are not objects with virtual methods, reducing overhead.
4.2 The Task Module: aria.task
This module interfaces with the M:N scheduler.


Code snippet




mod task {
   // Spawns an asynchronous task.
   // 'async func:f' is the coroutine to execute.
   // Returns a Future handle. The task starts immediately (eager execution).
   pub func:spawn<T> = Future<T>(async func:f) {... }

   // Spawns a blocking operation on the dedicated blocking thread pool.
   // The returned Future resolves when the blocking operation completes.
   // This effectively "asyncifies" synchronous code.
   pub func:spawn_blocking<T> = Future<T>(func:f) {... }

   // Cooperative yield. Suspends the current task and places it
   // at the back of the local run queue.
   pub async func:yield_now = void() {... }
   
   // Returns the ID of the current task.
   pub func:id = uint64() {... }
   
   // Block the current thread until the future completes.
   // This is the entry point for the async runtime from sync code.
   pub func:block_on<T> = Result<T>(Future<T>:fut) {... }
}

Usage Example:


Code snippet




use aria.task;
use aria.io; // Hypothethical IO module

async func:process_request = void(int:id) {
   // Async I/O (handled by M:N scheduler)
   string:data = await io.read_async("data.txt");
   
   // Heavy computation (offloaded to blocking pool)
   int:result = await task.spawn_blocking(func() {
       return heavy_math(data);
   });
   
   print(`Processed &{id}: &{result}`);
}

func:main = void() {
   // Entry into the async world
   task.block_on(async {
       // Spawn 1000 concurrent tasks
       for (i in 0..1000) {
           task.spawn(process_request(i));
       }
   });
}

________________
5. Synchronization Primitives
The distinction between blocking a thread and blocking a task is paramount. Aria must provide separate primitives for each context to avoid deadlocks and performance degradation.27
5.1 Mutex Design
The Async Mutex (aria.sync.Mutex):
Unlike a standard mutex which sleeps the thread, an async mutex interacts with the Waker system of the coroutine. If the lock is contested, the task is suspended, and its Waker is stored in a queue inside the mutex. When the lock is released, the Waker is signaled, re-scheduling the task.
The Sync Mutex (aria.thread.Mutex):
A wrapper around pthread_mutex_t or SRWLOCK. Using this inside an async block is dangerous because it blocks the worker thread.
API Design:


Code snippet




mod sync {
   // Asynchronous Mutex
   pub struct Mutex<T> {
       wild void*: state; // Internal pointer to wait queue
       T: data;           // Protected data
       
       // Returns a Future that resolves to a MutexGuard
       pub async func:lock = MutexGuard<T>(self);
   }
   
   // RAII Guard
   pub struct MutexGuard<T> {
       Mutex<T>*: lock_ref;
       
       // Accessor (smart pointer semantics)
       pub func:get = T*(self);
   }
}

Implementation Strategy:
The Mutex implementation should ideally be a hybrid. It should spin briefly (atomic CAS) to catch fast critical sections before falling back to the expensive path of suspending the coroutine and registering with the wait queue.28
5.2 Channels (Go-Style)
Aria channels should support both bounded (buffered) and unbounded modes. They serve as the primary communication primitive between tasks.
API Design:


Code snippet




mod sync {
   pub struct Channel<T>;
   
   pub func:channel<T> = tuple(Sender<T>, Receiver<T>)(int:capacity) {... }
   
   pub struct Sender<T> {
       // Suspends if channel is full (backpressure)
       pub async func:send = Result<void>(self, T:item);
       
       // Non-blocking try-send
       pub func:try_send = Result<void>(self, T:item);
   }
   
   pub struct Receiver<T> {
       // Suspends if channel is empty
       pub async func:recv = Result<T>(self);
       
       // Async iterator support: 'for msg in rx {... }'
       pub async func:next = Result<T>(self);
   }
}

Internal Mechanics:
The channel uses a lock-free ring buffer for data storage.
* Send: If space is available, CAS index and write. If full, create a waiter node with the current task's Waker and enqueue it in the send_waiters list. Suspend.
* Recv: If data is available, CAS index and read. If empty, enqueue Waker in recv_waiters. Suspend.
* Wakeup: When Recv consumes an item, it checks send_waiters. If a sender is waiting, it wakes it up.
5.3 Deadlock Prevention
In a hybrid model, deadlocks often occur when mixing sync and async locks.
* Constraint: The compiler (via the updated Borrow Checker) should emit a warning if a aria.thread.MutexGuard (synchronous) is held across an await point.29 This is because await yields the thread to other tasks; if the thread holds a lock while yielded, other tasks scheduled on that same thread (or others) waiting for that lock will never progress, causing a deadlock.
________________
6. Integration and Safety: Appendage Theory
Aria's "Appendage Theory" (Host # vs Appendage $) provides a unique advantage in concurrency safety.
The Theory:
* Host (#): The owner of the memory (pinned).
* Appendage ($): A reference dependent on the Host.
* Rule: Appendage lifetime $\le$ Host lifetime.
Concurrency Application:
To share data between threads/tasks, Aria must enforce traits similar to Rust's Send and Sync.30
1. Send Equivalent: A type T is Send if it is safe to move ownership of T to another thread.
   * TBB types (tbb8, etc.) are Send.
   * wild pointers are not Send (unless wrapped in an unsafe block).
   * GC types are Send if the GC is thread-safe (concurrent Mark-Sweep).
2. Sync Equivalent: A type T is Sync if &T (an appendage $T) is safe to access from multiple threads.
   * Mutex<T> is Sync if T is Send.
   * Immutable primitives are Sync.
Compiler Check:
The spawn function signature must strictly require Send for the closure and its captures.


Code snippet




// Generic constraints enforcing thread safety
pub func:spawn<T: Send> = Future<T>(async func:f);

If a developer attempts to capture a non-thread-safe type (like a raw wild pointer without synchronization) in a closure passed to spawn, the compiler will reject it based on the missing Send trait implementation.
________________
7. Comparative Analysis
Feature
	Aria (Proposed)
	Go (Goroutines)
	Rust (Tokio/Std)
	Java (Project Loom)
	Threading Model
	Hybrid (Explicit M:N + 1:1)
	Implicit M:N
	Hybrid (Explicit Async M:N + Std 1:1)
	Implicit M:N (Virtual Threads)
	Scheduling
	Work-Stealing (Chase-Lev)
	Work-Stealing
	Work-Stealing
	ForkJoinPool
	Stack Strategy
	Stackless (State Machines)
	Stackful (Segmented/Growable)
	Stackless (Futures/State Machines)
	Stackful
	Blocking I/O
	Explicit spawn_blocking
	Transparent (Netpoller)
	Explicit spawn_blocking
	Transparent (rewritten stdlib)
	Synchronization
	Async Mutex & Channels
	Channels (CSP)
	Async Mutex & Channels
	Sync Primitives (virtual-thread aware)
	Safety
	Appendage Theory / GC
	GC
	Ownership / Borrowing
	GC
	Zero-Cost?
	Yes (Manual dispatch)
	No (Runtime overhead)
	Yes (Zero-cost abstractions)
	No (JVM overhead)
	Key Takeaway:
Aria aligns most closely with Rust's model but simplifies the developer experience using its hybrid memory model. Unlike Go, Aria does not hide the cost of blocking operations, forcing developers to be intentional about performance boundaries via spawn_blocking. This explicit design avoids the performance "cliffs" seen in Go when FFI calls block the M:N scheduler.8
________________
8. Implementation Roadmap
Phase 1: The Core Scheduler (Weeks 1-3)
1. Implement the Chase-Lev Deque in C++ within the compiler backend.
2. Implement the Worker Thread Loop (Scan Local -> Steal -> Scan Global -> Park).
3. Define the CoroutineFrame structure layout in LLVM IR to support context switching.
Phase 2: Runtime Bridges (Weeks 4-5)
1. Implement spawn_blocking thread pool. This should be a separate std::vector<std::thread> that scales dynamically.
2. Implement block_on logic to drive the scheduler from the main thread.
Phase 3: Synchronization Primitives (Weeks 6-8)
1. Implement aria.sync.Channel using the lock-free queue primitives.
2. Implement aria.async.Mutex utilizing the coroutine Waker mechanism.
Phase 4: Integration & Testing (Weeks 9-10)
1. Integrate with aria.io (part of separate research) to ensure the reactor can wake tasks on the scheduler.
2. Stress test with "C10k" style benchmarks (10,000 concurrent connections) to verify memory stability and scheduler fairness.
9. Conclusion
The proposed concurrency model for Aria represents a synthesis of modern best practices. By adopting a hybrid M:N approach with work-stealing, Aria ensures high throughput for the networked applications of the future. Simultaneously, by retaining strict access to OS threads and enforcing safety via Appendage Theory, it maintains the low-level control required for systems programming. This design avoids the pitfalls of purely Green Thread models (FFI overhead) and purely OS Thread models (scalability limits), offering a pragmatic, high-performance solution that respects the constraints of modern hardware. The explicit spawn_blocking and block_on APIs serve as clear boundaries between the synchronous and asynchronous worlds, guiding developers toward performant, deadlock-free architectures.
________________
Report generated by: Senior Systems Architect & Language Design Analyst
Date: December 11, 2025
Ref: Task ID research_007_threading_library
Works cited
1. Threads - The Rust Programming Language - MIT, accessed December 11, 2025, https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/book/second-edition/ch16-01-threads.html
2. Threads: the difference of concurrency between many-to-one model and one-to-one model, accessed December 11, 2025, https://softwareengineering.stackexchange.com/questions/300927/threads-the-difference-of-concurrency-between-many-to-one-model-and-one-to-one
3. Using Threads to Run Code Simultaneously - The Rust Programming Language, accessed December 11, 2025, https://doc.rust-lang.org/book/ch16-01-threads.html
4. rust - Is it normal to experience large overhead using the 1:1 threading that comes in the standard library?, accessed December 11, 2025, https://stackoverflow.com/questions/47682291/is-it-normal-to-experience-large-overhead-using-the-11-threading-that-comes-in
5. Heavy weight and light weight thread - Stack Overflow, accessed December 11, 2025, https://stackoverflow.com/questions/2236412/heavy-weight-and-light-weight-thread
6. Lightweight threads and concurrency - Abhishek Shree, accessed December 11, 2025, https://abhishekshree.github.io/blog/goroutines
7. Go's Concurrency Model - Syntio, accessed December 11, 2025, https://www.syntio.net/en/labs-musings/gos-concurrency-model/
8. What are the disadvantages of an M:N threading model (e.g. goroutines)? - Stack Overflow, accessed December 11, 2025, https://stackoverflow.com/questions/44982392/what-are-the-disadvantages-of-an-mn-threading-model-e-g-goroutines
9. What are the disadvantages of an M:N threading model? : r/ProgrammingLanguages, accessed December 11, 2025, https://www.reddit.com/r/ProgrammingLanguages/comments/6mm4v1/what_are_the_disadvantages_of_an_mn_threading/
10. CompilerAudit_v0.0.7_INTEGRATED_20241207.txt
11. Why is async code in Rust considered especially hard compared to Go or just threads?, accessed December 11, 2025, https://www.reddit.com/r/rust/comments/16kzqpi/why_is_async_code_in_rust_considered_especially/
12. How to create a dedicated threadpool for CPU-intensive work in Tokio? - Stack Overflow, accessed December 11, 2025, https://stackoverflow.com/questions/61752896/how-to-create-a-dedicated-threadpool-for-cpu-intensive-work-in-tokio
13. Coroutines in LLVM — LLVM 22.0.0git documentation, accessed December 11, 2025, https://llvm.org/docs/Coroutines.html
14. injinj/WSQ: Work Stealing Queue, Job System, Thread Pool, Programming Parallel / Concurrent Applications - GitHub, accessed December 11, 2025, https://github.com/injinj/WSQ
15. Lock-free job stealing with modern c++, accessed December 11, 2025, https://manu343726.github.io/2017-03-13-lock-free-job-stealing-task-system-with-modern-c/
16. A fast work-stealing queue template library in modern C++ : r/cpp - Reddit, accessed December 11, 2025, https://www.reddit.com/r/cpp/comments/f0nu69/a_fast_workstealing_queue_template_library_in/
17. Job System 2.0: Lock-Free Work Stealing – Part 3 - Molecular Musings, accessed December 11, 2025, https://blog.molecular-matters.com/2015/09/25/job-system-2-0-lock-free-work-stealing-part-3-going-lock-free/
18. Working around the `'static` requirement in `tokio::task::spawn_blocking` - Rust Users Forum, accessed December 11, 2025, https://users.rust-lang.org/t/working-around-the-static-requirement-in-tokio-spawn-blocking/89831
19. spawn_blocking in tokio::task - Rust - Docs.rs, accessed December 11, 2025, https://docs.rs/tokio/latest/tokio/task/fn.spawn_blocking.html
20. Asynchronous Programming and the Tokio Runtime: A Beginner's Guide - Medium, accessed December 11, 2025, https://medium.com/@contactomyna/asynchronous-programming-and-the-tokio-runtime-a-beginners-guide-1a96cf89c82e
21. Dynamic Circular Work-Stealing Deque - Distributed Object Computing (DOC) Group for DRE Systems, accessed December 11, 2025, https://www.dre.vanderbilt.edu/~schmidt/PDF/work-stealing-dequeue.pdf
22. Atomic storage in Chase-lev deque - c++ - Stack Overflow, accessed December 11, 2025, https://stackoverflow.com/questions/57982348/atomic-storage-in-chase-lev-deque
23. How Tokio schedule tasks: A hard Lesson learnt - Rust Magazine, accessed December 11, 2025, https://rustmagazine.org/issue-4/how-tokio-schedule-tasks/
24. Understanding the Go Scheduler and discovering how it works | by Sanil Khurana - Medium, accessed December 11, 2025, https://medium.com/@sanilkhurana7/understanding-the-go-scheduler-and-looking-at-how-it-works-e431a6daacf
25. Work-Stealing Thread-pool : r/cpp - Reddit, accessed December 11, 2025, https://www.reddit.com/r/cpp/comments/m6z2fz/workstealing_threadpool/
26. Job System 2.0: Lock-Free Work Stealing – Part 1: Basics | Molecular Musings, accessed December 11, 2025, https://blog.molecular-matters.com/2015/08/24/job-system-2-0-lock-free-work-stealing-part-1-basics/
27. Bridge Async and Sync Code in Rust - Best Practices with Tokio - Greptime, accessed December 11, 2025, https://greptime.com/blogs/2023-03-09-bridging-async-and-sync-rust
28. c++ - Implement a high performance mutex similar to Qt's one - Stack Overflow, accessed December 11, 2025, https://stackoverflow.com/questions/29193445/implement-a-high-performance-mutex-similar-to-qts-one
29. What is the difference between std::sync::Mutex vs tokio - Stack Overflow, accessed December 11, 2025, https://stackoverflow.com/questions/73840520/what-is-the-difference-between-stdsyncmutex-vs-tokiosyncmutex
30. Memory-Safety Challenge Considered Solved? An In-Depth Study with All Rust CVEs - Zhuangbin Chen, accessed December 11, 2025, https://zbchern.github.io/papers/tosem21.pdf