Final Architectural Specification and Implementation Roadmap for the Aria Programming Language




1. Executive Summary and Strategic Synthesis


The landscape of modern systems programming is characterized by a stark dichotomy: the manual, granular control of resources offered by languages like C and C++, versus the safety and developer productivity provided by managed runtime environments such as Go, Java, and Python. The Aria programming language, as delineated in Specification Version 0.0.6 , proposes a radical unification of these paradigms. By integrating a hybrid memory model—defaulting to a generational garbage collector (GC) while permitting explicit "wild" unmanaged memory manipulation—Aria positions itself as a versatile tool capable of spanning the entire vertical stack, from high-level application logic to low-level systems engineering and embedded device control.
This comprehensive report serves as the definitive engineering artifact for the realization of the Aria language. It synthesizes the original implementation plan 1 with the core language specifications , while rigorously auditing the proposed architecture for logical consistency, operator precedence, and system stability. This analysis specifically targets the user's requirement to validate the plan against the specs, identifying gaps in logic, missing features, and opportunities for optimization.
The review confirms that the core concepts of Aria are sound but require significant architectural refinement to meet the "exhaustive detail" and "stability" requirements. Key findings include:
1. Logical Precedence Hazards: The original specification lists operators without defining their binding power. This report establishes a rigorous 21-level precedence table to resolve ambiguities, particularly concerning the interaction between the pipeline operator (|>), the ternary conditional (is), and assignment.
2. Control Flow Safety: The unique pick construct with explicit fall (fallthrough) introduces a potential resource leak hazard when combined with defer. A specialized Control Flow Graph (CFG) analysis pass is specified to ensure stack unwinding occurs before fallthrough jumps.
3. Ternary & Math Implementation: The implementation of ternary types (trit, nyte) and arbitrary precision integers (int512) requires specialized backend lowering strategies—specifically, the use of packed binary representations and AVX-512 vectorization—which were under-specified in the original plan.
4. I/O System Architecture: The requirement for a six-channel standard I/O system (stdout, stderr, stddbg, stdin, stddati, stddato) necessitates a bespoke runtime startup routine to manage file descriptors and prevent stream pollution.
This document integrates these findings into a unified, actionable implementation roadmap. It moves beyond a simple restatement of the plan to provide a deep technical blueprint for the compiler frontend, the LLVM-based backend, the hybrid runtime, and the developer tooling ecosystem.
________________


2. Architectural Philosophy and Design Principles


The successful implementation of Aria requires a deep understanding of its underlying design philosophy. Unlike languages that enforce a single memory model, Aria is "multi-paradigm" in the truest sense of resource management.


2.1 The Hybrid Memory Thesis


Aria’s central innovation is the coexistence of two distinct heaps:
1. The Managed Heap: Controlled by a Generational Mark-and-Sweep Garbage Collector. This is the default for obj, array, and string types. It optimizes for developer safety and ease of use.
2. The Wild Heap: Controlled by manual aria.alloc and aria.free calls. This optimizes for raw throughput, determinism, and interoperability with hardware or C libraries.
The critical engineering challenge—and the focus of much of this report—is the Bridge. The compiler must strictly enforce rules where these two worlds intersect to prevent "dangling pointers" (referencing freed wild memory) and "segmentation faults" (wild pointers accessing moved GC objects). The introduction of pinning (#) and safe references ($) provides the syntactical mechanism for this bridge, but the compiler's semantic analysis phase bears the burden of verification.


2.2 The "Systems + AI" Convergence


The inclusion of native tensor types (tensor, matrix), vector intrinsics (vec9), and ternary logic (trit) suggests Aria is designed for a post-binary, AI-centric computing era.1
* Implication: The compiler backend cannot treat these as simple arrays. They must be first-class citizens in the Intermediate Representation (IR) to leverage hardware accelerators (NPUs, TPUs) and SIMD instructions (AVX-512, NEON) effectively.
* Optimization: The plan prioritizes "Structure of Arrays" (SoA) layouts for tensors to maximize cache locality, a critical factor for machine learning workloads.
________________


3. Development Environment and Toolchain Specification


To ensure the long-term stability and reproducibility of the Aria compiler, the build environment is strictly standardized. The complexity of building a self-hosting compiler that links against a specific version of LLVM mandates a containerized approach.


3.1 The Dockerized Build Infrastructure


The development environment is defined by a multi-stage Dockerfile based on Ubuntu 24.04 LTS (Noble Numbat).1 This choice is strategic:
* Glibc Compatibility: Ubuntu LTS provides a stable glibc version (2.39+), ensuring that binaries produced are forward-compatible with the vast majority of Linux distributions used in enterprise and cloud environments.
* Toolchain Availability: It offers native access to GCC 13 and CMake 3.28, which are prerequisites for bootstrapping LLVM 19.
Stage 1: The Toolchain Builder
We do not rely on pre-packaged LLVM binaries. Aria requires specific experimental targets (e.g., WebAssembly, RISC-V) and configurations (Polly polyhedral optimizer) that are often disabled in standard builds.
* Source: llvm-project (Version 19.1.x).
* Build Flags:
   * CMAKE_BUILD_TYPE=Release (for compiler speed)
   * LLVM_ENABLE_PROJECTS="clang;lld;lldb;polly"
   * LLVM_TARGETS_TO_BUILD="X86;AArch64;ARM;WebAssembly;RISC-V"
   * LLVM_ENABLE_ASSERTIONS=ON (Critical for debugging compiler crashes during development)
* Artifacts: The build produces llvm-config, libLLVM.so, and the Clang frontend, which are installed to /opt/llvm-19.
Stage 2: The Aria Development Context
This stage imports the artifacts from Stage 1 into a fresh image to minimize size.
* Dependencies:
   * ninja-build: For parallel incremental builds.
   * valgrind & gdb: For debugging the wild allocator and runtime crashes.
   * libssl-dev: For the crypto module.
   * zlib1g-dev: For compression support in the standard library.
   * appimagetool: For packaging the final distribution.


3.2 LLVM 19 Integration Strategy


Aria leverages specific features of LLVM 19 that map directly to its requirements:
1. Opaque Pointers (ptr): LLVM 15+ transitioned to opaque pointers, removing pointee types (e.g., i8* vs i32*). Aria adopts this fully. It simplifies the lowering of wild (void*) and dyn (dynamic) types, as the IR no longer enforces strict pointer typing. Type safety is enforced entirely by the Aria frontend, decoupling the logical type system from the physical memory representation.
2. Scalable Vector Extension (SVE): To support tensor and matrix types, the backend targets LLVM’s scalable vector types (e.g., <vscale x 4 x float>). This allows the generated machine code to adapt at runtime to the vector width of the host CPU, whether it's a 128-bit SSE unit or a 512-bit AVX-512 unit.
3. ORC JIT: The computeOptimalSize() function and compile-time logic require JIT capabilities. We link against LLVM's On-Request Compilation (ORC) JIT libraries to execute Aria code segments during the compilation phase ("comptime").
________________


4. The Type System: Architecture and Implementation


Aria's type system is the foundation of its expressiveness. It spans from single bits to arbitrary precision integers and complex tensor structures.


4.1 The Integer Hierarchy


The specification lists a power-of-two hierarchy: int1, int2, int4, int8... int512.
Aria Type
	Bit Width
	Implementation Strategy
	Arithmetic Handling
	int1 (bool)
	1
	LLVM i1
	Native boolean logic.
	int2 - int4
	2 - 4
	LLVM i8 (masked)
	Operations mask upper bits after every calc.
	int8 - int64
	8 - 64
	LLVM i8 - i64
	Native CPU instructions.
	int128
	128
	LLVM i128
	Native on x64 (using pair of registers); library call on ARM32.
	int256
	256
	Array [4 x i64]
	Software emulation via compiler-rt or AVX2 intrinsics.
	int512
	512
	Array [8 x i64]
	Software emulation with AVX-512 optimization.
	Optimization for int512:
Standard software emulation for 512-bit math is slow. The Aria backend will detect AVX-512 support on the host. If present, it will emit vector instructions to perform parallel addition/subtraction on the 64-bit limbs of the large integer, utilizing mask registers for carry propagation. This can yield a 4x-8x speedup over scalar emulation.


4.2 Ternary Logic Implementation


The types trit, tryte, nit, and nyte introduce base-3 logic to a binary machine.
* Representation Challenge: Binary bits (0, 1) cannot efficiently map to ternary trits (-1, 0, 1) without waste. A single trit contains $\approx 1.58$ bits of information.
* The "Packed Nyte" Strategy:
   * Trit: Stored as int8 (values -1, 0, 1). We sacrifice storage for ALU speed.
   * Nyte: Defined as 5 trits. $3^5 = 243$. This fits exactly into a uint8 (0-255).
   * Tryte: Defined as 6 trits. $3^6 = 729$. Stored as uint16.
* Arithmetic Lowering: The compiler uses Look-Up Tables (LUTs) for ternary operations. Instead of computing (a + b) % 3 with expensive division instructions, the compiler emits a load from a pre-computed 3x3 result matrix.
   * Memory Cost: Negligible (a few bytes per operation type).
   * Performance: Single memory access latency (L1 cache) vs multi-cycle division.


4.3 Floating Point and Arbitrary Precision


* flt32, flt64: Map to IEEE 754 single and double precision.
* flt128: Maps to fp128 (quad precision). On x86, this often uses the 80-bit x87 FPU padded to 128 bits, or software emulation (libquadmath).
* flt256, flt512: These do not exist in hardware. The implementation will link against the MPFR library (Multiple Precision Floating-Point Reliable) to provide software implementations. Note: These operations will be significantly slower and are intended for scientific simulation, not real-time graphics.


4.4 Linear Algebra Primitives


* vec2, vec3: Lowered to <2 x float> and <3 x float> LLVM vectors. Passed in SIMD registers.
* vec9: A 3x3 matrix flattened. Lowered to <9 x float>. Since 9 is not a power of 2, LLVM will often pad this to <16 x float> (512-bit) or split it into registers.
* tensor: A dynamic multi-dimensional array.
   * Struct Layout:
C
struct Tensor {
   void* data;          // Pointer to element 0
   uint64_t* shape;     // Array of dimension sizes
   uint64_t* strides;   // Array of memory steps
   uint64_t offset;     // Offset from data ptr
   uint8_t rank;        // Number of dimensions
   uint8_t dtype;       // Element type enum
};

   * Strided Access: Supporting tensor requires the compiler to generate nested loops where the memory index is computed as $i \times stride + j \times stride +...$.
   * Optimization: For dense tensors (default), strides are monotonic. The compiler simplifies the index calculation to a single linear counter for element-wise operations (e.g., tensor + tensor).
________________


5. The Memory Model: Wild, GC, and The Bridge


Aria's memory model is its most critical subsystem. It defines how the language balances safety and performance.


5.1 The Wild Allocator


The wild keyword opts out of garbage collection.
   * Allocator: The runtime integrates mimalloc (by Microsoft) as the backing allocator for aria.alloc(). Mimalloc is chosen for its superior performance in concurrent workloads compared to standard malloc, utilizing thread-local free lists to avoid lock contention.
   * Behavior: wild pointers are simple addresses. They support arithmetic (p++, p + 5).
   * Safety Hazard: The compiler does not track the lifetime of wild memory. However, to improve user-friendliness, we introduce a Debug Mode Bounds Checker. In debug builds, wild pointers are "fat pointers" (address + size). Accessing out of bounds triggers a panic. In release builds, this is stripped for raw speed.


5.2 The Garbage Collector (GC)


For obj, array, string, Aria uses a custom GC.
   * Algorithm: Generational Mark-and-Sweep.
   * Nursery (Gen 0): A bump-pointer allocator. Allocation is just ptr += size. Extremely fast. When full, a minor collection copies live objects to the Old Generation.
   * Old Gen (Gen 1): A mark-and-sweep collector using free-lists.
   * Write Barriers: To maintain the generational invariant (Old objects cannot point to New objects without being tracked), the compiler injects a Write Barrier before every pointer assignment:
C
// aria code: old_obj.field = new_obj;
if (is_old(old_obj) && is_new(new_obj)) {
   card_table_mark(old_obj);
}
old_obj.field = new_obj;



5.3 The Bridge: Pinning and Safe References


The intersection of Wild and GC memory is the source of most potential bugs.
      * Pinning (# operator):
      * Syntax: wild int* ptr = #gc_array;
      * Semantics: The GC must be informed not to move gc_array during compaction.
      * Implementation: The object header has a PINNED bit. The # operator sets this bit. The compiler automatically inserts code to unset the bit when the ptr goes out of scope (RAII style).
      * Safe References ($ operator):
      * Syntax: till(100, 1) { print($); }
      * Semantics: $ is a read-only, stack-allocated view of a value.
      * Implementation: $ is treated as a const reference. It cannot be reassigned. This guarantees that within the loop or scope, the value is stable.
________________


6. Compiler Frontend: Syntax, Semantics, and AST


The frontend transforms source code into the Abstract Syntax Tree (AST). This section addresses the user's specific request to review operator precedence and parsing logic.


6.1 Operator Precedence and Associativity


The specification lists many operators but lacks a precedence table. Without this, expressions like a + b |> func are ambiguous. Below is the definitive precedence table for Aria, designed to adhere to standard mathematical logic while accommodating functional pipelines and unique Aria operators.
Table 2: Aria Operator Precedence (Highest to Lowest)
Level
	Operators
	Associativity
	Description
	1
	(), ``, .
	Left-to-Right
	Function call, Array subscript, Member access
	2
	?., !!
	Left-to-Right
	Safe navigation, Non-null assertion (implied)
	3
	?
	Left-to-Right
	Unwrap operator (postfix)
	4
	!, ~, ++, --, #, @, $
	Right-to-Left
	Logical/Bitwise Not, Inc/Dec, Pin, Address, Iteration var
	5
	**
	Right-to-Left
	Exponentiation (Standard Math)
	6
	*, /, %
	Left-to-Right
	Multiplicative
	7
	+, -
	Left-to-Right
	Additive
	8
	<<, >>
	Left-to-Right
	Bitwise Shifts
	9
	<=>
	Left-to-Right
	Spaceship (Three-way comparison)
	10
	<, <=, >, >=
	Left-to-Right
	Relational
	11
	==, !=
	Left-to-Right
	Equality
	12
	&
	Left-to-Right
	Bitwise AND
	13
	^
	Left-to-Right
	Bitwise XOR
	14
	|
	Left-to-Right
	Bitwise OR
	15
	&&
	Left-to-Right
	Logical AND
	16
	||
	Left-to-Right
	Logical OR
	17
	??
	Right-to-Left
	Null Coalescing
	18
	is
	Right-to-Left
	Ternary Conditional (cond is true : false)
	19
	.., ...
	Left-to-Right
	Range (Inclusive/Exclusive)
	20
	|>, <|
	Left-to-Right
	Pipeline (Forward/Backward)
	21
	=, +=, -=, *=, etc.
	Right-to-Left
	Assignment
	22
	=>
	Right-to-Left
	Lambda declaration
	Critical Logic Check:
      * Pipelines (|>) at Level 20: This is crucial. It ensures that a + b |> func parses as (a + b) |> func, not a + (b |> func). It allows data transformations to occur after the math is done.
      * Unwrap (?) at Level 3: High precedence allows func()? + 1 to work (unwrap the result, then add 1).
      * Ternary (is) at Level 18: Lower than math and logic, so x > 5 is "big" : "small" parses correctly as (x > 5) is....


6.2 Complex Control Flow: The pick Construct


The pick statement is a multi-conditional branching tool.
      * Structure:
Code snippet
pick(c) {
   (<9) { fall(fail); }
   (10..20) {... }
   (*) {... }
}

      * Logic Hazard: The fall keyword (explicit fallthrough) acts as a goto. If the current block contains defer statements or pinned objects (#), a naive jump would bypass the cleanup code, causing memory leaks or permanent pinning.
      * The Fix: The compiler must perform Control Flow Graph (CFG) analysis.
         1. Identify the target label of a fall.
         2. Identify all cleanup actions (defers, unpins) required to exit the current block.
         3. Emit the cleanup code before the jump instruction.
         4. Verify that the target label is a valid entry point (i.e., it does not skip variable initializations in the target block).


6.3 Template Literals and Interpolation


The spec uses backticks with &{} for interpolation.
         * Lexing Strategy: The lexer requires a stack of states.
         1. Encounter ` -> Push STRING state.
         2. Encounter &{ -> Push CODE state.
         3. Encounter } (inside CODE) -> Pop state (return to STRING).
         4. Encounter ` (inside STRING) -> Pop state.
         * Benefit: This supports recursive interpolation: `Value: &{ val + &{ offset } }`.
________________


7. The Runtime System: Concurrency, I/O, and Processes


The runtime is the engine that executes Aria's logic.


7.1 M:N Concurrency Scheduler


Aria uses Green Threads (coroutines) mapped to OS threads.
         * Structure:
         * M: User-space Tasks (created via spawn(func) or async).
         * N: OS Threads (Workers). Usually N = CPU Cores.
         * Work Stealing: Each Worker has a local Deque (Double-ended queue) of tasks.
         * Push: New tasks go to the bottom of the local deque.
         * Pop: The worker executes from the bottom (LIFO) to maximize cache locality.
         * Steal: If empty, the worker steals tasks from the top (FIFO) of another worker's deque.
         * Context Switching: Since Aria compiles to native code, context switching is done via assembly logic that saves the callee-saved registers (RBX, RBP, R12-R15 on x64) and swaps the stack pointer (RSP).


7.2 The Six-Channel I/O System


The user specification includes standard streams plus stddbg, stddati, and stddato.
         * Implementation: The runtime startup routine (crt0 equivalent) must initialize these.
         * stdin (0), stdout (1), stderr (2): Standard POSIX streams.
         * stddbg (3): Debug Channel. If the OS didn't open FD 3, the runtime opens /dev/null or a log file. This allows separating clean output (stdout) from logs (stddbg).
         * stddati (4) & stddato (5): Data Channels. Dedicated to binary payload (e.g., image data piped between processes) while stdin/stdout handle control text (JSON/commands).
         * Benefit: This solves the common problem in Unix tools where status messages corrupt the binary output of a pipe.


7.3 Process Management


         * spawn: The spec uses spawn for both internal tasks and external processes.
         * Differentiation: Overloading. spawn(func) creates a coroutine. spawn(string) uses posix_spawn to create a child process.
         * Result: spawn(string) returns a process object containing the PID and pipes.
         * createPipe: Wraps the pipe2 syscall to create unidirectional data channels for IPC.
________________


8. Standard Library and Module System


The Standard Library (std) is the "batteries included" layer.


8.1 Module Resolution (mod, use)


         * Logical vs Physical:
         * use std.io; resolves to $ARIA_HOME/std/io.aria.
         * use "./utils.aria"; resolves to a relative path.
         * Visibility: pub makes symbols visible. By default, everything is private (internal to the module).
         * Circular Dependencies: The compiler uses a multi-pass symbol collection phase. Pass 1 collects all type names. Pass 2 resolves bodies. This allows Module A to use types from Module B even if Module B imports A.


8.2 Functional Primitives


         * filter, transform (map), reduce: Implemented as Generics.
         * Optimization: When used with the pipeline operator |>, these functions return Iterators, not Arrays. This enables lazy evaluation.
         * Code Gen: array |> filter(f) |> map(g) compiles into a single loop: for x in array { if f(x) { yield g(x) } }. No intermediate memory allocation.


8.3 System Diagnostics


         * getMemoryUsage(): On Linux, reads /proc/self/statm.
         * getActiveConnections(): Reads /proc/net/tcp.
         * Performance Note: These are expensive system calls/file reads. They should not be used in tight loops.
________________


9. Recommendations for Optimization, Stability, and User Experience


To satisfy the request for additions that make Aria "faster, more stable, and more user friendly":


9.1 Optimizations (Faster)


         1. Tail Call Optimization (TCO): The compiler should identify recursive calls in tail position and convert them to jumps (jmp). This prevents stack overflow in recursive algorithms, which are common in the functional patterns Aria encourages.
         2. Structure of Arrays (SoA) Automatic Transformation: For tensor types, the compiler should optionally transform Array-of-Structs to Struct-of-Arrays layout to maximize SIMD efficiency.
         3. Profile-Guided Optimization (PGO): The build tool should support a two-pass compilation. Pass 1 builds an instrumented binary. The user runs their test suite. Pass 2 recompiles using the execution profile to optimize hot paths.


9.2 Stability Improvements


         1. Strict Wild Mode: A compiler flag (--strict-wild) that enforces defer usage for every wild allocation, ensuring no memory leaks in unmanaged code.
         2. Sanitizer Integration: Integrate LLVM's AddressSanitizer (ASan) and ThreadSanitizer (TSan). A build flag --sanitize=address would link the ASan runtime to catch buffer overflows in wild memory during development.


9.3 User Friendliness (UX)


         1. LSP (Language Server Protocol): Don't just build a compiler. Build an aria-lsp binary. This provides autocomplete, go-to-definition, and hover documentation in VS Code / Vim / Emacs.
         2. Formatter (aria fmt): A rigid, opinionated code formatter built into the toolchain (like gofmt). This eliminates style debates.
         3. Error Diagnostics: Borrow Rust’s error style. Instead of "Error: Type mismatch", say:"Expected int8, found trit. trit uses ternary logic (-1, 0, 1) and cannot be implicitly cast to binary int8. Try using cast<int8>(my_trit)."
________________


10. Implementation Roadmap


This roadmap transforms the plan into a phased execution strategy.


Phase 0: The Bootstrap (Months 1-3)


         * Goal: A minimal compiler written in C++ that can compile a subset of Aria.
         * Deliverable: aria-boot binary.
         * Scope: int types, if/else, while, basic wild memory. No GC, no Async.


Phase 1: Self-Hosting & Core Logic (Months 4-8)


         * Goal: Rewrite the compiler in Aria.
         * Deliverable: aria-stage1 binary.
         * Scope:
         * Implement the GC (Nursery + Mark/Sweep).
         * Implement pick lowering with the CFG fix.
         * Implement the Precedence Parser.
         * Implement trit/nyte packed storage.


Phase 2: Runtime & Concurrency (Months 9-12)


         * Goal: Full language features.
         * Deliverable: aria-stage2 binary.
         * Scope:
         * M:N Scheduler.
         * 6-Channel I/O system.
         * async/await state machine generation.
         * tensor SIMD lowering.


Phase 3: Polish & Distribution (Months 13+)


         * Goal: Production release.
         * Deliverable: aria-v1.0.0-x86_64.AppImage.
         * Scope:
         * StdLib optimization (Assembly tuning for math).
         * LSP and Formatter tools.
         * AppImage packaging with standard library sources.
________________


11. Conclusion


The Aria programming language represents a complex but viable convergence of high-level expressivity and low-level control. By synthesizing the specification with a rigorous implementation plan, we have identified the critical path to success. The hybrid memory model, while challenging, offers a unique value proposition: the safety of a script with the power of a systems language.
The additions made in this report—specifically the operator precedence table, the control flow safety analysis for pick/fall, the packed ternary representation, and the six-channel I/O architecture—fill the gaps in the original specification. With the Dockerized build system and the AppImage distribution strategy, the Aria toolchain is designed for modern, reproducible deployment. The path is clear for the engineering team to begin Phase 0.
Works cited
         1. aria_v0_0_6_specs.txt